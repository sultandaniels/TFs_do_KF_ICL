{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Script to Compute the Relative Entropy Rate between the Observations of Two Linear Systems \n",
    "(Second version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import linalg_helpers as la_help\n",
    "import control as ct\n",
    "import compute_relative_entropy as com_rel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_A(nx, W, type=\"gauss\", cond_num_threshold=np.inf):\n",
    "    cond_num = np.inf\n",
    "    while cond_num >= cond_num_threshold:\n",
    "        if type == \"gauss\":\n",
    "            A = np.sqrt(0.33)*np.random.randn(nx, nx)\n",
    "            max_eig = np.max(np.abs(la.eigvals(A)))\n",
    "            A = 0.95*A / max_eig\n",
    "        elif type == \"upptri\":\n",
    "            A = np.diag(np.random.uniform(-1, 1, nx)) * 0.95\n",
    "            A[np.triu_indices(nx, 1)] = np.random.uniform(-1, 1, (nx ** 2 + nx) // 2 - nx)\n",
    "\n",
    "        Pi = ct.dlyap(A, W).astype(np.float64)\n",
    "        cond_num = np.linalg.cond(Pi)\n",
    "    print(\"cond_num of Pi: \", cond_num)\n",
    "\n",
    "    return A.astype(np.float64), Pi\n",
    "\n",
    "def generate_random_C(nx, ny, Pi, noise_sigma, E=1, zero_C=False):\n",
    "    if zero_C:\n",
    "        C = np.zeros((ny, nx))\n",
    "    else:\n",
    "        C = np.sqrt(0.333333333)*np.random.randn(ny, nx)\n",
    "    V = (noise_sigma**2)*np.eye(ny).astype(np.float64) \n",
    "\n",
    "    obs_tr = np.trace(C @ Pi @ C.T + V)\n",
    "\n",
    "    if obs_tr < 0:\n",
    "        print(\"obs_tr negative:\", obs_tr)\n",
    "        print(\"evals of Pi\", eval)\n",
    "        print(\"evals greater than 0?\", np.greater(eval, 0))\n",
    "        print(\"all positive\", np.all(np.greater(eval, 0)))\n",
    "        print(\"eval of CPiCT:\", la.eig(C @ Pi @ C.T))\n",
    "        raise ValueError(\"Didn't catch negative evals\")\n",
    "    \n",
    "    alpha = np.sqrt(E / obs_tr)\n",
    "\n",
    "    C = alpha*C\n",
    "    sigma_v = alpha*noise_sigma\n",
    "    V = np.eye(ny) * (sigma_v ** 2)\n",
    "\n",
    "    print(\"trace:\", np.trace(C@Pi@C.T + V))\n",
    "    return C.astype(np.float64), V.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 2\n",
    "ny = 2\n",
    "noise_std = 1e-1\n",
    "\n",
    "context = 8\n",
    "\n",
    "# C = np.block([np.eye(ny), np.zeros((ny, nx-ny))]).astype(np.float64) # observable\n",
    "W = (noise_std**2)*np.eye(nx).astype(np.float64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond_num of Pi:  4.0169892631732305\n",
      "cond_num of Pi:  18.342593826814305\n",
      "trace: 1.0000000000000002\n",
      "trace: 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "A,Pi = generate_random_A(nx, W)\n",
    "Ap,Pi_p = generate_random_A(nx, W, type=\"gauss\")\n",
    "\n",
    "C, V = generate_random_C(nx, ny, Pi, noise_std)\n",
    "Cp, Vp = generate_random_C(nx, ny, Pi_p, noise_std, zero_C=True)\n",
    "\n",
    "# A = 0.95*np.eye(nx)\n",
    "# Pi = ct.dlyap(A, W).astype(np.float64)\n",
    "# Ap = 0.9*np.eye(nx)\n",
    "# Pi_p = ct.dlyap(Ap, W).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond num of CPiC^T + V:  1.0\n",
      "cond num of CPi_pC^T + V:  1.0\n",
      "trace num of CPiC^T + V:  1.0000000000000002\n",
      "trace num of CPi_pC^T + V:  0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "print(\"cond num of CPiC^T + V: \", np.linalg.cond(C @ Pi @ C.T + V))\n",
    "print(\"cond num of CPi_pC^T + V: \", np.linalg.cond(Cp @ Pi_p @ Cp.T + Vp))\n",
    "print(\"trace num of CPiC^T + V: \", np.trace(C @ Pi @ C.T + V))\n",
    "print(\"trace num of CPi_pC^T + V: \", np.trace(Cp @ Pi_p @ Cp.T + Vp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 0\n",
      "cond(K_k): 1.0\n",
      "k: 1\n",
      "cond(K_k): 1.0\n",
      "k: 2\n",
      "cond(K_k): 1.0\n",
      "k: 3\n",
      "cond(K_k): 1.0\n",
      "k: 4\n",
      "cond(K_k): 1.0\n",
      "k: 5\n",
      "cond(K_k): 1.0\n",
      "k: 6\n",
      "cond(K_k): 1.0\n",
      "k: 7\n",
      "cond(K_k): 1.0\n",
      "ran for context: 8\n",
      "Matrix K_k @ K_k^inv:\n",
      "    1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000 \n",
      "k: 0\n",
      "cond(K_k): 1.0\n",
      "k: 1\n",
      "cond(K_k): 1.0\n",
      "k: 2\n",
      "cond(K_k): 1.0\n",
      "k: 3\n",
      "cond(K_k): 1.0\n",
      "k: 4\n",
      "cond(K_k): 1.0\n",
      "k: 5\n",
      "cond(K_k): 1.0\n",
      "k: 6\n",
      "cond(K_k): 1.0\n",
      "k: 7\n",
      "cond(K_k): 1.0\n",
      "ran for context: 8\n",
      "Matrix K_k @ K_k^inv:\n",
      "    1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000     0.0000 \n",
      "    0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     0.0000     1.0000 \n"
     ]
    }
   ],
   "source": [
    "Kn, Kinvs, Finvs = com_rel.compute_cov_inv(A,C,V,Pi, context)\n",
    "Kn_p, Kinvs_p, Finvs_p = com_rel.compute_cov_inv(Ap,Cp,Vp,Pi_p, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(Kn, Kn_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute rel ent rate function\n",
    "\n",
    "(using natural log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_k(Kinv, ny):\n",
    "    return Kinv[:ny, :ny]\n",
    "\n",
    "def G_k(Kinv, ny):\n",
    "    return Kinv[:ny, ny:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(finvs):  8\n",
      "k: 1\n",
      "first term: 0.0\n",
      "second term: 0.0\n",
      "k: 2\n",
      "first term: 0.0\n",
      "second term: 0.0\n",
      "k: 3\n",
      "first term: 0.0\n",
      "second term: 0.0\n",
      "k: 4\n",
      "first term: 0.0\n",
      "second term: 0.0\n",
      "k: 5\n",
      "first term: 0.0\n",
      "second term: 0.0\n",
      "k: 6\n",
      "first term: 0.0\n",
      "second term: 0.0\n",
      "k: 7\n",
      "first term: 0.0\n",
      "second term: 0.0\n",
      "rel_ent:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "rel_ent = []\n",
    "print(\"len(finvs): \", len(Finvs))\n",
    "\n",
    "for k in range(context):\n",
    "\n",
    "    Gk = G_k(Kinvs[k], ny)\n",
    "    Gpk = G_k(Kinvs_p[k], ny)\n",
    "    Fk = F_k(Kinvs[k], ny)\n",
    "    Fpk = F_k(Kinvs_p[k], ny)\n",
    "    if k ==0:\n",
    "        K0 = com_rel.K_k(Kn,ny,0)\n",
    "        K0_p = com_rel.K_k(Kn_p,ny,0)\n",
    "        \n",
    "        rel_ent.append(0.5*(np.log(la.det(K0_p)) - np.log(la.det(K0)) + np.trace(Kinvs_p[k]@K0 - np.eye(ny)))) #from Polyanskiy and Wu Ex. 2.2 (non conditional relative entropy between two multivariate gaussians)\n",
    "    else:\n",
    "        print(\"k:\", k)\n",
    "        print(\"first term:\", np.log(la.det(Finvs[k])) - np.log(la.det(Finvs_p[k])))\n",
    "        print(\"second term:\", ny - np.trace(Finvs[k]@Fpk) - np.trace((Gk.T@Finvs[k]@Fpk@Finvs[k]@Gk - 2*Gpk.T@Finvs[k]@Gk + Gpk.T@Finvs_p[k]@Gpk)@Kinvs[k-1] ) )\n",
    "        rel_ent.append(rel_ent[k-1] - 0.5*(ny + np.log(la.det(Finvs[k])) - np.log(la.det(Finvs_p[k])) - np.trace(Finvs[k]@Fpk) - np.trace((Gk.T@Finvs[k]@Fpk@Finvs[k]@Gk - 2*Gpk.T@Finvs[k]@Gk + Gpk.T@Finvs_p[k]@Gpk)@Kinvs[k-1] ) )    )\n",
    "\n",
    "print(\"rel_ent: \", rel_ent)\n",
    "rel_ent_rates = [x / y for x, y in zip(rel_ent, range(1, len(rel_ent) + 1))]\n",
    "rel_ent_rates = np.array(rel_ent_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the relative entropy rate vs the context\n",
    "logscale=False\n",
    "if logscale:\n",
    "    intercept = 0.032\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "else:\n",
    "    intercept = 0.0\n",
    "\n",
    "plt.plot(range(context), rel_ent_rates-intercept, marker=\".\")\n",
    "plt.xlabel(\"context\")\n",
    "plt.ylabel(\"relative entropy rate\")\n",
    "plt.title(\"Relative Entropy Rate vs Context\")\n",
    "\n",
    "# plt.ylim([-0.25, 20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the powers of $A$ and the first row of $K_N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'linalg_helpers' has no attribute 'compute_powers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m A_powers \u001b[38;5;241m=\u001b[39m \u001b[43mla_help\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_powers\u001b[49m(A, context)\n\u001b[1;32m      3\u001b[0m values \u001b[38;5;241m=\u001b[39m C\u001b[38;5;129m@A_powers\u001b[39m\u001b[38;5;129m@Pi\u001b[39m\u001b[38;5;129m@C\u001b[39m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(context):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'linalg_helpers' has no attribute 'compute_powers'"
     ]
    }
   ],
   "source": [
    "A_powers = la_help.compute_powers(A, context)\n",
    "\n",
    "values = C@A_powers@Pi@C.T\n",
    "for i in range(context):\n",
    "    la_help.print_matrix(values[i], f\"C A^{i} Π C^T\")\n",
    "\n",
    "# values = la_help.lower_threshold_matrix(values, 1e-5)\n",
    "# for i in range(context):\n",
    "#     la_help.print_matrix(values[i], f\"C A^{i} Π C^T thresholded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $K_N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Kn:  (50, 50)\n"
     ]
    }
   ],
   "source": [
    "Kn = la_help.block_toeplitz(values) + la_help.create_repeated_block_diagonal(V, context)\n",
    "print(\"shape of Kn: \", Kn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let $K_k^{-1} = \\begin{bmatrix}\n",
    "    F_k & G_k\\\\\n",
    "    G_k^T & H_k\n",
    "\\end{bmatrix}$.\n",
    "\n",
    "### Computing the Block Inverse Matrices\n",
    "Let us give the off-diagonal blocks of $K_k$ the name $K_{off}$. This means, $K_k \\triangleq \\begin{bmatrix}\n",
    "    K_{0} & K_{off}\\\\\n",
    "    K_{off}^T & K_{k-1}\n",
    "\\end{bmatrix}$.\n",
    "\\begin{align}\n",
    "    &K_k K_k^{-1} = I\\\\ \n",
    "    &\\Rightarrow K_0 F_k + K_{off} G_k^T = I; \\,\\, K_{off}^T G_k + K_{k-1} H_k = I; \\,\\, K_0 G_k + K_{off} H_k = \\mathbf{0}; \\,\\, \\text{and } K_{off}^T F_k + K_{k-1} G_k^T = \\mathbf{0}\\\\\n",
    "    &\\Rightarrow F_k = \\left(K_0 - K_{off}K_{k-1}^{-1}K_{off}^T\\right)^{-1}; \\\\ \n",
    "    &G_k = -F_k K_{off}K_{k-1}^{-1};\\\\\n",
    "    &\\text{and } H_k = K_{k-1}^{-1}\\left(I - K_{off}^T G_k\\right).\n",
    "\\end{align}\n",
    "\n",
    "#### Remark\n",
    "$F_k^{-1} = K_0 - K_{off}K_{k-1}^{-1}K_{off}^T$ requires no extra inverse because $K_{k-1}^{-1}$ is computed on the previous iteration. Furthermore $F_k^{-1} \\in \\R{m\\times m}$ always, so computing $F_k$ only requires the inversion of a small matrix compared to the dimension of $K_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute $F_k^{-1}$, $G_k^{-1}$, and $K_k^{-1}$ for all $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_k(Kn, k):\n",
    "    # The k-th Covariance matrix for the observation process\n",
    "    return Kn[-ny*(k+1):, -ny*(k+1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigvals of K0: [1.7288974  0.28881186 0.43538825 0.8025     0.76926803]\n",
      "eigvals of Pi: [1.34967128 0.41611701 0.26497633 0.16979608 0.15427598 0.12513894\n",
      " 0.10000592 0.1047625  0.11146293 0.1092621 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"eigvals of K0:\", abs(la.eigvals(C@Pi@C.T + V)))\n",
    "print(\"eigvals of Pi:\", abs(la.eigvals(Pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran for context: 10\n",
      "Matrix K_k @ K_k^inv:\n",
      "    1.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000 \n",
      "    0.0000     1.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000 \n",
      "   -0.0000    -0.0000     1.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000    -0.0000     0.0000     1.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "   -0.0000     0.0000    -0.0000     0.0000     1.0000     0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000    -0.0000    -0.0000     0.0000    -0.0000     1.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     1.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     1.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000 \n",
      "    0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     1.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "   -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     1.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     1.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     1.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     1.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     1.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "   -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     1.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     1.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     1.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     1.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000 \n",
      "    0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     1.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "   -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     1.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     1.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     1.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     1.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     1.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     1.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     1.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     1.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     1.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000 \n",
      "    0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     1.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "   -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     1.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     1.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000     1.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     1.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     1.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     1.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     1.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     1.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     1.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     1.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000     1.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     1.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     1.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     1.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     1.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     1.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000    -0.0000     1.0000    -0.0000     0.0000    -0.0000    -0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     1.0000    -0.0000     0.0000     0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000     1.0000    -0.0000     0.0000 \n",
      "    0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     1.0000     0.0000 \n",
      "   -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000    -0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000     0.0000    -0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000     0.0000    -0.0000     0.0000    -0.0000     1.0000 \n"
     ]
    }
   ],
   "source": [
    "Kinvs = []\n",
    "Finvs = []\n",
    "for k in range(context):\n",
    "    if k == 0:\n",
    "        Kinvs.append(la.inv(K_k(Kn, 0)))\n",
    "    else:\n",
    "        # la_help.print_matrix(K_k(Kn,k), f\"K_{k}\")\n",
    "        K0 = K_k(Kn, 0)\n",
    "        Koff = K_k(Kn, k)[:ny, ny:]\n",
    "\n",
    "        Finv = (K0 - Koff@Kinvs[k-1]@Koff.T)\n",
    "        Finvs.append(Finv)\n",
    "\n",
    "        Fk = la.inv(Finv)\n",
    "        if not np.allclose(Fk@Finv, np.eye(ny), atol=1e-10):\n",
    "            la_help.print_matrix(Fk@Finv, \"Fk @ Finv\")\n",
    "            raise ValueError(\"Fk is not the inverse of Finv\")\n",
    "        \n",
    "        Gk = -Fk@Koff@Kinvs[k-1]\n",
    "        Hk = Kinvs[k-1]@(np.eye(ny*k) - Koff.T@Gk)\n",
    "        Kinvs.append(np.block([[Fk, Gk], [Gk.T, Hk]]))\n",
    "\n",
    "        if not np.allclose(K_k(Kn, k)@Kinvs[k], np.eye(ny*(k+1)), atol=1e-5):\n",
    "            print(\"k:\", k)\n",
    "            print(\"eigvals of Kinvs[k]:\", np.sort(np.real(la.eigvals(Kinvs[k])))[::-1])\n",
    "            print(\"eigvals of K_k\", np.sort(np.real(la.eigvals(K_k(Kn, k))))[::1])\n",
    "            la_help.print_matrix(Koff, \"Koff\")\n",
    "            la_help.print_matrix(Fk, \"Fk\")\n",
    "            la_help.print_matrix(Finv, \"Finv\")\n",
    "            la_help.print_matrix(Gk, \"Gk\")\n",
    "            la_help.print_matrix(K_k(Kn, k)@Kinvs[k], \"K_k @ K_k^inv\")\n",
    "            context = k\n",
    "            raise ValueError(\"K_k^inv is not the inverse of K_K\")\n",
    "    \n",
    "print(\"ran for context:\", context)\n",
    "la_help.print_matrix(K_k(Kn, k)@Kinvs[k], \"K_k @ K_k^inv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
